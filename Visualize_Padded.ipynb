{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T01:11:48.857389Z",
     "iopub.status.busy": "2025-06-11T01:11:48.857154Z",
     "iopub.status.idle": "2025-06-11T01:11:50.846681Z",
     "shell.execute_reply": "2025-06-11T01:11:50.846163Z",
     "shell.execute_reply.started": "2025-06-11T01:11:48.857368Z"
    }
   },
   "outputs": [],
   "source": [
    "from NCA import *\n",
    "import arc_agi_utils as aau\n",
    "import cv2\n",
    "import vft\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from utils import make_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ed51de60ffef90",
   "metadata": {},
   "source": [
    "# Make path for videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "140fceda7b51ebec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T01:11:50.847818Z",
     "iopub.status.busy": "2025-06-11T01:11:50.847376Z",
     "iopub.status.idle": "2025-06-11T01:11:50.851478Z",
     "shell.execute_reply": "2025-06-11T01:11:50.850999Z",
     "shell.execute_reply.started": "2025-06-11T01:11:50.847796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: Saved_frames created\n"
     ]
    }
   ],
   "source": [
    "path_video = \"Saved_frames\"\n",
    "make_path(path_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c693b2e7d4ca04",
   "metadata": {},
   "source": [
    "# Video making functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1854abe6082dc8ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T01:11:50.852700Z",
     "iopub.status.busy": "2025-06-11T01:11:50.852183Z",
     "iopub.status.idle": "2025-06-11T01:11:50.861352Z",
     "shell.execute_reply": "2025-06-11T01:11:50.860832Z",
     "shell.execute_reply.started": "2025-06-11T01:11:50.852671Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_frame(x, path, frame_number, height, width, chn):\n",
    "    image_np = x.clone().detach().cpu().permute(0,3,2,1).numpy().clip(0,1)[0,:,:,:3]\n",
    "    plt.imsave(f\"{path}/frame_{frame_number}.png\", image_np)\n",
    "\n",
    "def make_video(path, total_frames, height, width, vid_num = \"r\"):\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(path+'/' +vid_num+'.mp4', fourcc, 15.0, (height, width))\n",
    "    for frame_number in range(total_frames):\n",
    "       frame_path = path+f\"/frame_{frame_number}.png\"\n",
    "       frame = cv2.imread(frame_path)\n",
    "       #frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "       frame = cv2.flip(frame,1)\n",
    "       frame = cv2.rotate(frame,cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "       frame = cv2.resize(frame, (height, width), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "       out.write(frame)\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89da0c562b313c4d",
   "metadata": {},
   "source": [
    "# CA settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7268acfeee0705d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T01:11:50.862539Z",
     "iopub.status.busy": "2025-06-11T01:11:50.861990Z",
     "iopub.status.idle": "2025-06-11T01:11:50.870837Z",
     "shell.execute_reply": "2025-06-11T01:11:50.870349Z",
     "shell.execute_reply.started": "2025-06-11T01:11:50.862518Z"
    }
   },
   "outputs": [],
   "source": [
    "DEVICE = vft.DEVICE\n",
    "CHANNELS = vft.CHANNELS\n",
    "BATCH_SIZE = vft.BATCH_SIZE\n",
    "MASKING = vft.MASKING\n",
    "GENESIZE = vft.GENESIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fb3b361f64d7c",
   "metadata": {},
   "source": [
    "# Load ARC-AGI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a0999bb4003a3b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T01:11:50.872167Z",
     "iopub.status.busy": "2025-06-11T01:11:50.871522Z",
     "iopub.status.idle": "2025-06-11T01:11:51.030470Z",
     "shell.execute_reply": "2025-06-11T01:11:51.029394Z",
     "shell.execute_reply.started": "2025-06-11T01:11:50.872147Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ArcData/data/trainingarc-agi_training_challenges.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m training_path = \u001b[33m\"\u001b[39m\u001b[33mArcData/data/training\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m eval_path = \u001b[33m\"\u001b[39m\u001b[33mArcData/data/evaluation\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m (inputs, outputs), (eval_in, eval_out)= \u001b[43maau\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m max_train = aau.max_n_colors(inputs, outputs)\n\u001b[32m      6\u001b[39m max_eval = aau.max_n_colors(eval_in, eval_out)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/NCA2/arc_agi_utils.py:20\u001b[39m, in \u001b[36mimport_data\u001b[39m\u001b[34m(path, device)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mimport_data\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, device: \u001b[38;5;28mstr\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mcuda:0\u001b[39m\u001b[33m\"\u001b[39m) -> (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     training_challenges = \u001b[43mload_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43marc-agi_training_challenges.json\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     training_solutions = load_json(path + \u001b[33m'\u001b[39m\u001b[33marc-agi_training_solutions.json\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     22\u001b[39m     t = \u001b[38;5;28mlist\u001b[39m(training_challenges)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/NCA2/arc_agi_utils.py:13\u001b[39m, in \u001b[36mload_json\u001b[39m\u001b[34m(file_path)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_json\u001b[39m(file_path):\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     14\u001b[39m         data = json.load(f)\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'ArcData/data/trainingarc-agi_training_challenges.json'"
     ]
    }
   ],
   "source": [
    "training_path = \"ArcData/data/training\"\n",
    "eval_path = \"ArcData/data/evaluation\"\n",
    "(inputs, outputs), (eval_in, eval_out)= aau.import_data(training_path)\n",
    "\n",
    "max_train = aau.max_n_colors(inputs, outputs)\n",
    "max_eval = aau.max_n_colors(eval_in, eval_out)\n",
    "max_colors = max(max_train, max_eval) +1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6582c3afb579101b",
   "metadata": {},
   "source": [
    "# Problems to test per model (you can choose your own)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbeb1e459539597",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-11T01:11:51.031001Z",
     "iopub.status.idle": "2025-06-11T01:11:51.031239Z",
     "shell.execute_reply": "2025-06-11T01:11:51.031135Z",
     "shell.execute_reply.started": "2025-06-11T01:11:51.031124Z"
    }
   },
   "outputs": [],
   "source": [
    "v3 = {0, 11, 12, 14, 15, 16, 17, 21, 27, 28, 29, 33, 35, 38, 44, 48, 59, 61, 63, 66, 68, 72, 77, 81, 91, 92, 94, 97, 99, 107, 109, 112, 113, 122, 123, 127, 134, 135, 138, 139, 149, 150, 154, 160, 161, 163, 169, 170, 172, 176, 179, 182, 188, 196, 198, 206, 211, 212, 214, 217, 218, 222, 223, 226, 231, 235, 240, 242, 247, 253, 258, 265, 274, 275, 285, 291, 294, 303, 306, 308, 314, 316, 317, 320, 321, 329, 333, 341, 342, 343, 344, 348, 350, 355, 360, 361, 362, 374, 376, 377, 380, 384, 390, 394, 396, 397, 398, 399}\n",
    "\n",
    "\n",
    "\n",
    "v4 = {7, 12, 140, 24, 154, 155, 159, 162, 41, 169, 172, 49, 185, 69, 205, 208, 209, 213, 89, 94, 222, 103, 107, 116, 118, 120, 249}\n",
    "v1 = {191, 258, 3, 103, 169, 208, 81, 209, 116, 213, 150, 254, 24, 185, 154, 222, 159}\n",
    "ca = {7, 136, 140, 142, 24, 159, 162, 41, 169, 172, 49, 185, 63, 191, 69, 71, 205, 209, 213, 89, 94, 223, 103, 231, 235, 118, 120, 254}\n",
    "test = {0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac96b3149382ab73",
   "metadata": {},
   "source": [
    "# Make Videos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fb4bb14c306ab4",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-11T01:11:51.032484Z",
     "iopub.status.idle": "2025-06-11T01:11:51.032889Z",
     "shell.execute_reply": "2025-06-11T01:11:51.032720Z",
     "shell.execute_reply.started": "2025-06-11T01:11:51.032702Z"
    }
   },
   "outputs": [],
   "source": [
    "for problem in v3:\n",
    "\n",
    "\n",
    "    mode = \"rgb\"\n",
    "    genes = [i for i in range(GENESIZE)]\n",
    "    nca_in = [aau.pad_to_size([32,32],aau.arc_to_nca_space(max_colors, ip, CHANNELS,GENESIZE, mode=mode, gene_location=genes, is_invis=1)) for id,ip in enumerate(inputs[problem])]\n",
    "    nca_out = [aau.pad_to_size([32,32], aau.arc_to_nca_space(max_colors, ip, CHANNELS,GENESIZE, mode=mode, gene_location=genes, is_invis=1)) for id,ip in enumerate(outputs[problem])]\n",
    "\n",
    "    eval_nca_in = [aau.pad_to_size([32,32], aau.arc_to_nca_space(max_colors, ip, CHANNELS,GENESIZE, mode=mode, gene_location=genes, is_invis=1)) for id,ip in enumerate(eval_in[problem])]\n",
    "    eval_nca_out = [aau.pad_to_size([32,32], aau.arc_to_nca_space(max_colors, ip, CHANNELS,GENESIZE, mode=mode, gene_location=genes, is_invis=1)) for id,ip in enumerate(eval_out[problem])]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        nca = EngramNCA_v3(CHANNELS, vft.GENE_HIDDEN_N ,vft.GENE_PROP_HIDDEN_N, GENESIZE)\n",
    "        nca.load_state_dict(torch.load(f\"TrainedARCModels/{type(nca).__name__}/problem_\" +str(problem)+\".pth\"))\n",
    "        nca = nca.to(DEVICE)\n",
    "\n",
    "    nca.eval()\n",
    "\n",
    "\n",
    "    image_np = aau.nca_to_rgb_image(eval_nca_in[0])[:,:,:4]*255\n",
    "    image_np = cv2.resize(image_np, (10 * image_np.shape[1], 10 * image_np.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "    image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(\"Saved_frames/Saved_start_and_end/\"  + type(nca).__name__ +\"problem_start_\" + str(problem)+\".jpg\", image_np)\n",
    "\n",
    "    image_np = aau.nca_to_rgb_image(eval_nca_out[0])[:, :, :4] * 255\n",
    "    image_np = cv2.resize(image_np, (10 * image_np.shape[1], 10 * image_np.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "    image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(\"Saved_frames/Saved_start_and_end/\" + type(nca).__name__ + \"problem_end_\" + str(problem) + \".jpg\",\n",
    "                image_np)\n",
    "\n",
    "\n",
    "    x = eval_nca_in[0].tile(1,1,1,1)\n",
    "\n",
    "    for i in range(128):\n",
    "        x = nca(x, 0.5)\n",
    "        x = x.detach()\n",
    "        write_frame(x, path_video, i, 10*x.shape[3],10*x.shape[2], CHANNELS)\n",
    "\n",
    "    make_video(path_video, 128, 10*x.shape[3],10*x.shape[2], type(nca).__name__ +\"problem_\" + str(problem) +\"padded\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
